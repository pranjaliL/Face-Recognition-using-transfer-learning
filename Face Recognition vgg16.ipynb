{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = int(224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input('Enter your name (without space) to label the image folder : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent Directory path \n",
    "parent_dir = \"/Users/box/Desktop/mlops-ws/photos_dataset/training/\"\n",
    "  \n",
    "# Path \n",
    "path = os.path.join(parent_dir,name)\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliph(photo):\n",
    "    ifliph = np.zeros(photo.shape).astype('uint8')\n",
    "    for i in range(0,photo.shape[0]):\n",
    "        ifliph[photo.shape[0]-i-1,:] = photo[i,:]\n",
    "    return ifliph\n",
    "\n",
    "def flipv(photo):\n",
    "    iflipv = np.zeros(photo.shape).astype('uint8')\n",
    "    for i in range(0,photo.shape[0]):\n",
    "        iflipv[:,i] = photo[:,photo.shape[0]-i-1]\n",
    "    return iflipv\n",
    "\n",
    "def r270(photo):\n",
    "    iflip270 = np.zeros(photo.shape).astype('uint8')\n",
    "    for i in range(0,photo.shape[0]):\n",
    "        iflip270[photo.shape[0]-i-1,:] = photo[:,i]\n",
    "    return iflip270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_extractor(photo):\n",
    "    cord = face_classifier.detectMultiScale(photo)    \n",
    "    if cord is ():\n",
    "        return None\n",
    "    photo = cv2.resize(photo,(shape,shape))\n",
    "    return photo\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 200 samples of your face from webcam input to make 1600 images\n",
    "while True:\n",
    "    status , photo = cap.read()\n",
    "    print(status)\n",
    "    if status == True:\n",
    "        photo = face_extractor(photo)\n",
    "        if photo is not None:\n",
    "            \n",
    "            scount = count*8 + 1  #for one photo will become 8 photos\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,photo)\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,fliph(photo))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,flipv(photo))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,r270(photo))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,fliph(r270(photo)))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,flipv(r270(photo)))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,fliph(flipv(r270(photo))))\n",
    "\n",
    "            scount += 1\n",
    "            file_name_path = path.format(name) + str(scount) + '.jpg'\n",
    "            cv2.imwrite(file_name_path,flipv(fliph(photo)))\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(photo, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Display', photo)\n",
    "\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(1) == 27 or count == 200: #27 is the Escape Key\n",
    "            break\n",
    "            \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving 400 images from train to test database\n",
    "\n",
    "#generate random 400 numbers from 1 to 1600\n",
    "test = np.random.randint(low=1, high=1600, size=400)\n",
    "for i in range(0,350):\n",
    "    command = 'mv /Users/box/Desktop/mlops-ws/photos_dataset/training/pranjali'.format(name) + str(test[i]) + '.jpg ' + '/Users/box/Desktop/mlops-ws/photos_dataset/testing/' + name\n",
    "    #print(command)\n",
    "    #command is 'mv source_file destination_folder'\n",
    "    #change above command as per your os\n",
    "    sb.getoutput(command)\n",
    "\n",
    "print(\"Generating Database complete\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now data set of your face has been created. so we will be working on creating a model for prediction using transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "#Loads the VGG16 model \n",
    "model = VGG16(weights = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop (2).h5', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.layers:\n",
    "    i.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = model.output\n",
    "\n",
    "top_model = Flatten(name = \"flatten\")(top_model)\n",
    "top_model = Dense(256,activation='relu')(top_model)\n",
    "top_model = Dense(2, activation = \"sigmoid\")(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilig the new model\n",
    "newmodel = Model(inputs=model.input,outputs=top_model)\n",
    "\n",
    "#newmodel.layers\n",
    "newmodel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = '/Users/box/Desktop/mlops-ws/photos_dataset/training/'\n",
    "validation_data_dir = '/Users/box/Desktop/mlops-ws/photos_dataset/testing/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"nface_classifier.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# Note we use a very small learning rate \n",
    "newmodel.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 2565\n",
    "nb_validation_samples = 635\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "history = newmodel.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "newmodel.save(\"nface_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('nface_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "status , image = cap.read()\n",
    "print(status)\n",
    "nimage = cv2.resize(image,(224,224))\n",
    "aimage = np.expand_dims(nimage, axis=0)\n",
    "finalimage = preprocess_input(aimage)\n",
    "pred = classifier.predict(finalimage)\n",
    "name = 'person'\n",
    "if pred[0][0] == 1.0:\n",
    "    name = 'Pranjali'\n",
    "else :\n",
    "    name = 'not found'\n",
    "cv2.putText(image, name, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "cv2.imshow('livestream',image)\n",
    "if cv2.waitKey() == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
